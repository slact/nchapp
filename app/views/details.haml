%h1="Details"
%p
  While Nchan is designed to be straightforward to configure and use, it has its quirks. Some are the result of being a module for a general-purpose web server, some are features that have not yet been implemented, and others are there to expose extra features for the brave developer.

.tableOfContents
  
%a(href="#publisher-endpoint-configs")
  %h2#publisher-endpoint-configs="Publisher Endpoints, Locations, and Configurations"

:markdown
  *A channel's configuration is set to the that of its last-used publishing location.*

  Recall that Nchan configuration maps server *locations* to channel publisher and subscriber *endpoints*. Most of the time, you'll want just one publisher and one subscriber endpoint per channel. But what if differently configured publisher endpoints map to the same channel?
  
  Let's say you have the following configuration:

  ```nginx
    location = /pub/nobuffer {
      nchan_publisher;
      nchan_channel_id foo;
      nchan_store_messages off;
    }
    
    location = /pub/bigbuffer {
      nchan_publisher;
      nchan_channel_id foo;
      nchan_message_buffer_length 30;
      nchan_message_timeout 10m;
    }
    
    location = /sub/weird_settings {
      nchan_subscriber;
      nchan_channel_id foo;
      nchan_subscriber_first_message oldest;
    }
  ``` 

  Let's also assume I have two command-line scripts, [`pub.rb`](https://github.com/slact/nchan/blob/master/dev/pub.rb) and [`sub.rb`](https://github.com/slact/nchan/blob/master/dev/sub.rb) for publishing and subscribing respectively.
  
  What happens if you publish to the channel `foo` from different locations, say, first through `POST /pub/bigbuffer`, then `POST /pub/nobuffer`?
  
  ```console
  > ./pub.rb --response --once --message "msg1" /pub/bigbuffer
   Publishing to http://localhost:80/pub/bigbuffer.
   202
   queued messages: 1
   last requested: 0 sec. ago
   active subscribers: 0
   last message id: 1449346161:0
  
  > ./pub.rb --response --once --message "msg2" /pub/bigbuffer
   Publishing to http://localhost:80/pub/bigbuffer.
   202
   queued messages: 2
   last requested: 4 sec. ago
   active subscribers: 0
   last message id: 1449346165:0
  
  > ./pub.rb --response --once --message "msg3" /pub/bigbuffer
   Publishing to http://localhost:80/pub/bigbuffer. 
   202
   queued messages: 3
   last requested: 10 sec. ago
   active subscribers: 0
   last message id: 1449346171:0
  
  > ./sub.rb --id /sub/weird_settings                       
   Subscribing 1 longpoll client to http://localhost:80/sub/weird_settings.
   Timeout: 60sec, quit msg: FIN
   <1449346161:0> msg1
   <1449346165:0> msg2
   <1449346171:0> msg3
  ^C^C
  
  > ./pub.rb --response --once --message "nomsg" /pub/nobuffer
   Publishing to http://localhost:80/pub/nobuffer.
   201
   queued messages: 0
   last requested: 5 sec. ago
   active subscribers: 0
   last message id: 1449346793:0
  
  > ./sub.rb --id /sub/weird_settings                         
   Subscribing 1 longpoll client to http://localhost:80/sub/weird_settings.
   Timeout: 60sec, quit msg: FIN
   ^C^C
  
  > ./pub.rb --response --once --message "another1" /pub/bigbuffer
   Publishing to http://localhost:80/pub/bigbuffer.
   202
   queued messages: 1
   last requested: 9 sec. ago
   active subscribers: 0
   last message id: 1449346804:0
  
  > ./pub.rb --response --once --message "another2" /pub/bigbuffer
   Publishing to http://localhost:80/pub/bigbuffer.
   202
   queued messages: 2
   last requested: 12 sec. ago
   active subscribers: 0
   last message id: 1449346809:0
  
  > ./sub.rb --id /sub/weird_settings
   Subscribing 1 longpoll client to http://localhost:80/sub/weird_settings.
   Timeout: 60sec, quit msg: FIN
   <1449346804:0> another1
   <1449346809:0> another2
  ^C^C
  ```
  
  
  All messages published before publishing to `/pub/nobuffer` are deleted, because the request to `/pub/nobuffer` disables the channel `foo`'s message buffer, clearing out all its' stored messages. Publishing to `/pub/bigbuffer` afterwards restored message storage, as this applied that location's config to the channel `foo`.
  
  This applies to all publishing-related configuration settings, which at present are  
  - `nchan_message_buffer_length`
  - `nchan_message_timeout`
  - `nchan_use_redis`
  
  So, if you want a channel to behave consistently, and want to publish to it from multiple locations, *make sure those locations have the same configuration*.
  
  You can also can use differently-configured publisher locations to dynamically update a channel's message retention settings. This can be used to erase messages or to scale an existing channel's message retention as desired.

%a(href="#securing-channels")
  %h2#securing-channels="Securing Channels"
:markdown
  ### Securing Publisher Endpoints
  Consider the use case of an application where authenticated users each use a private, dedicated channel for live updates. The configuration might look like this:
  
  ```nginx
  http {
    server {
      #available only on localhost
      listen  127.0.0.1  8080;
      location ~ /pub/(\w+)$ {
        nchan_publisher;
        nchan_channel_group my_app_group;
        nchan_channel_id $1;
      }
    }
    
    server {
      #available to the world
      listen 80;
      location ~ /sub/(\w+)$ {
        nchan_subscriber;
        nchan_channel_group my_app_group;
        nchan_channel_id $1;
      }
    }
  }
  
  ```

  Here, the subscriber endpoint is available on a public-facing port 80, and the publisher endpoint is only available on localhost, so can be accessed only by applications residing on that machine.
  
  ### Keeping the Channel Private
  
  A Channel ID that is meant to be private should be treated with the same care as a session ID token. Considering the above use case of one-channel-per-user, how can we ensure that only the authenticated user, and no one else, is able to access his channel? 
  
  First, if you intend on securing the channel contents, you must use TLS/SSL:
  
  ```nginx 
  http {
    server {
      #available only on localhost
      listen  127.0.0.1  8080;
      #...publisher endpoint config
    }
    server {
      #available to the world
      listen 443 ssl;
      #SSL config goes here
      location ~ /sub/(\w+)$ {
        nchan_subscriber;
        nchan_channel_group my_app_group;
        nchan_channel_id $1;
      }
    }
  }
  ```
  
  Now that you have a secure connection between the subscriber client and the server, you don't need to worry about the channel ID or messages being passively intercepted. This is a minimum requirement for secure message delivery, but it is not sufficient. 
  
  You must also take care to do at least one of the following:
    - [Generate good, high-entropy Channel IDs](#generate-good-channel-ids).
    - [Authorize all subscribers with the `nchan_authorize_request` config directive](#authenticate-with-nchan_authorize_request).
    - [Authorize subscribers and hide channel IDs with the "`X-Accel-Redirect`" mechanism](#authenticate-and-hide-the-channel-id-with-x-accel-redirect).
    
  #### Generate Good Channel IDs
  
  An ID that can be guessed is an ID that can be hijacked. If you are not authenticating subscribers (as described below), a channel ID should be impossible to guess. Use at least 128 bits of entropy to generate a random token, associate it with the authenticated user, and share it only with the user's client. Do not reuse tokens, just as you would not reuse session IDs.
  
  #### Authenticate and hide the channel ID with X-Accel-Redirect

  This method uses the [X-Accel feature](https://www.nginx.com/resources/wiki/start/topics/examples/x-accel) of Nginx upstream proxies to perform an internal request to a subscriber endpoint.
  It allows a subscriber client to be authenticated by your application, and then redirected by nginx internally to a location chosen by your appplication (such as a publisher or subscriber endpoint). This makes it possible to have securely authenticated clients that are unaware of the channel id they are subscribed to.
  
  Consider the following configuration:
  ```nginx 
  upstream my_app {
    server 127.0.0.1:8080;
  }

  server {
    listen 80; 
    
    location = /sub_upstream {
      proxy_pass http://upstream_app/subscriber_x_accel_redirect;
      proxy_set_header X-Forwarded-For $remote_addr;
    }
    
    location ~ /sub/internal/(\w+)$ {
      internal; #this location only accessible for internal nginx redirects
      nchan_subscriber;
      nchan_channel_id $1;
      nchan_channel_group test;
    }
  }
  ```
  
  As commented, `/sub/internal/` is inaccessible from the outside:
  ```console
  > curl  -v  http://127.0.0.1/sub/internal/foo
   
   < HTTP/1.1 404 Not Found
   < Server: nginx/1.9.5
   <
   <html>
   <head><title>404 Not Found</title></head>
   <body bgcolor="white">
   <center><h1>404 Not Found</h1></center>
   <hr><center>nginx/1.9.5</center>
   </body>
   </html>
  ```
  
  But if a request is made to `/sub_upstream`, it gets forwarded to your application (`my_app`) on port 8080 with the url `/subscriber_x_accel_redirect`.
  Note that you can set any forwarded headers here like any [`proxy_pass`](http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_pass) Nginx location, 
  but unlike the case with `nchan_authorize_request`, Nchan-specific variables are not available.
  
  Now, your application must be set up to handle the request to `/subscriber_x_accel_redirect`. You should make sure the client is properly authenticated (maybe using a session cookie), and generate an associated channel id. If authentication fails, respond with a normal `403 Forbidden` response.
  
  If your application succesfully authenticates the subscriber request, you now need to instruct Nginx to issue an internal redirect to `/sub/internal/my_channel_id`.
  This is accomplished by responding with an empty `200 OK` response that includes two headers:
  - `X-Accel-Redirect: /sub/internal/my_channel_id`
  - `X-Accel-Buffering: no`
  
  In the presence of these headers, Nginx will not forward your app's response to the client, and instead will *internally* redirect to `/sub/internal/my_channel_id`. 
  This will behave as if the client had requested the subscriber endpoint location directly.
  
  Thus using X-Accel-Redirect it is possible to both authenticate all subscribers *and* keep channel IDs completely hidden from subscribers.
  
  This method is especially useful for EventSource and Websocket subscribers. Long-Polling subscribers will need to be re-authenticated for every new message, which may flood your application with too many authentication requests.

%a(href="#application-callbacks")
  %h2#application-callbacks="Callbacks, Hooks, and Application Integration"
:markdown
  There are several ways an application can interface with Nchan during the publishing and subscribing process:
  
  ### Request Authorization
  
  This method behaves just like the Nginx [http_auth_request module](http://nginx.org/en/docs/http/ngx_http_auth_request_module.html#auth_request_set).
  
  Consider the configuration:
  ```nginx
    upstream my_app {
      server 127.0.0.1:8080;
    }
    location = /auth {
      proxy_pass http://my_app/pubsub_authorize;
      proxy_pass_request_body off;
      proxy_set_header Content-Length "";
      proxy_set_header X-Subscriber-Type $nchan_subscriber_type;
      proxy_set_header X-Publisher-Type $nchan_publisher_type;
      proxy_set_header X-Prev-Message-Id $nchan_prev_message_id;
      proxy_set_header X-Channel-Id $nchan_channel_id;
      proxy_set_header X-Original-URI $request_uri;
      proxy_set_header X-Forwarded-For $remote_addr;
    }
    
    location ~ /pubsub/auth/(\w+)$ {
      nchan_channel_id $1;
      nchan_authorize_request /auth;
      nchan_pubsub;
      nchan_channel_group test;
    }
  ```
  
  Here, any request to the location `/pubsub/auth/<...>`
  will need to be authorized by your application (`my_app`). Nginx will generate a `GET /pubsub_authorize` request to the application, with additional headers set by the `proxy_set_header` directives. Note that Nchan-specific variables are available for this authorization request.
  Once your application receives this request, it should decide whether or not to authorize the subscriber. This can be done based on a forwarded session cookie, IP address, or any set of parameters of your choosing. If authorized, it should respond with an empty `200 OK` response, and the client will be subscribed to the channel. Otherwise, respond with a `403 Forbidden`, and this will be forwarded to the client.
  
  Note that Websocket and EventSource clients will only try to authorize during the first handshake request, and Long-Poll and Interval-Poll subscribers will need to be authorized each time they request the next message, which may flood your application with too many authorization requests.

  
  ### Subsribe and Unsubscribe Callbacks
  
  Subscribers can report to an application when they have swubscribed and unsubscribed to a channel using the `nchan_subscribe_request` and `nchan_unsubscribe_request` settings. These should point to Nginx locations configured to forward requests to an upstream proxy (your application):
  
  ```nginx
    location ~ /sub/(\w+)$ {
      nchan_channel_id $1;
      nchan_subscribe_request /upstream/sub;
      nchan_unsubscribe_request /upstream/unsub;
      nchan_subscriber;
      nchan_channel_group test;
    }

    location = /upstream/unsub {
      proxy_pass http://127.0.0.1:9292/unsub;
      proxy_ignore_client_abort on;  #!!!important!!!!
      proxy_set_header X-Subscriber-Type $nchan_subscriber_type;
      proxy_set_header X-Channel-Id $nchan_channel_id;
      proxy_set_header X-Original-URI $request_uri;
    } 
    location = /upstream/sub {
      proxy_pass http://127.0.0.1:9292/sub;
      proxy_set_header X-Subscriber-Type $nchan_subscriber_type;
      proxy_set_header X-Message-Id $nchan_message_id;
      proxy_set_header X-Channel-Id $nchan_channel_id;
      proxy_set_header X-Original-URI $request_uri;
    } 
  ```
  
  In order for `nchan_unsubscribe_request` to work correctly, the location it points to must have `proxy_ignore_client_abort on;`. Otherwise, suddenly abborted subscribers may not trigger an unsubscribe request.
  
  Note that the subscribe/unsubscribe hooks are **disabled for long-poll and interval-poll clients**, because they would trigger these hooks each time they receive a message.
  
  ### Message Publishing Callbacks
  
  Messages can be sent to an upstream application before being published using the `nchan_publisher_upstream_request` setting:
  
  ```nginx
    location ~ /pub/(\w+)$ {
      #publisher endpoint
      nchan_channel_id $1;
      nchan_pubsub;
      nchan_publisher_upstream_request /upstream_pub;
    }
    
    location = /upstream_pub {
      proxy_pass http://127.0.0.1:9292/pub;
      proxy_set_header X-Publisher-Type $nchan_publisher_type;
      proxy_set_header X-Prev-Message-Id $nchan_prev_message_id;
      proxy_set_header X-Channel-Id $nchan_channel_id;
      proxy_set_header X-Original-URI $request_uri;
    } 
  ```
  With this configuration, incoming messages are first `POST`ed to `http://127.0.0.1:9292/pub`.
  The upstream response code determines how publishing will proceed:
    - `304 Not Modified` publishes the message as received, without modifification.
    - `204 No Content` discards the message
    - `200 OK` is used for modifying the message. Instead of the original incoming message, the message contained in this HTTP response is published.
  
  There are two main use cases for `nchan_publisher_upstream_request`: forwarding incoming data from Websocket publishers to an application, and mutating incoming messages.
  
%a(href="#using-redis")
  %h2#using-redis="Using Redis"
:markdown
  [Redis](http://redis.io)
  can be used to add **data persistence** and **horizontal scalability** to your Nchan setup. 
  
  ### Connecting to a Redis Server
  To connect to a single Redis master server, use the `nchan_redis_url` and `nchan_use_redis` settings:
  
  ```nginx
  http {
    nchan_redis_url "redis://redis_server:6379";
    server {
      listen 80;
      
      location ~ /redis_sub/(\w+)$ {
        nchan_subscriber;
        nchan_channel_id $1;
        nchan_use_redis on;
        nchan_channel_group "redis_backed_channel";
      }
      location ~ /redis_pub/(\w+)$ {
        nchan_publisher;
        nchan_channel_id $1;
        nchan_use_redis on;
        nchan_channel_group "redis_backed_channel";
      }
      
      location ~ /regular_sub/(\w+)$ {
        nchan_subscriber;
        nchan_channel_id $1;
        nchan_channel_group noredis;
      }
      location ~ /regular_pub/(\w+)$ {
        nchan_publisher;
        nchan_channel_id $1;
        nchan_channel_group noredis;
      }
    }
  } 
  ```
  
  All servers with the above configuration connecting to the same redis server share channel and message data.
  
  All redis-backed publisher and subscriber endpoints [must be configured](#publisher-endpoint-configs) with `nchan_use_redis on;`.
  Channels that never use redis can be configured side-by-side with redis-backed channels, provided the endpoints never overlap. (This can be ensured, as above, by setting separate `nchan_channel_group`s.). Different locations can also connect to different Redis servers.
  
  
  ### Redis Cluster
  Since version 1.0.0, Nchan also supports using Redis Cluster, which adds scalability via sharding channels among cluster nodes. Redis cluster also provides **automatic failover**, **high availability**, and eliminates the single point of failure of one shared Redis server. It is configred and used like so:
  
  ```nginx
  http {
    upstream redis_cluster {
      nchan_redis_server redis://127.0.0.1:7000;
      nchan_redis_server redis://127.0.0.1:7001;
      nchan_redis_server redis://127.0.0.1:7002;
      # you don't need to specify all the nodes, they will be autodiscovered
      # however, it's recommended that you do specify at least a few master nodes.
    }
    server {
      listen 80;
      
      location ~ /sub/(\w+)$ {
        nchan_subscriber;
        nchan_channel_id $1;
        nchan_redis_pass redis_cluster;
      }
      location ~ /pub/(\w+)$ {
        nchan_publisher;
        nchan_channel_id $1;
        nchan_redis_pass redis_cluster;
      }
    }
  } 
  ```

  #### High Availability
  Redis Cluster connections are designed to be resilient and try to recover from errors. Interrupted connections will have their commands queued until reconnection, and Nchan will publish any messages missed while disconnected. Nchan is also adaptive to cluster modifications. It will add new nodes and remove them as needed.
  
  
  **All Nchan servers sharing a Redis server or cluster must have their times synchronized (via ntpd or your favorite ntp daemon). Failure to do so may result in missed or duplicate messages.**
  
  Redis Cluster support is a new feature. It's fairly well-tested, but there may still be bugs. Please help test it and report any problems!
  
%a(href="#introspection")
  %h2#using-redis="Introspection"
%p
  :markdown

    There are several ways to see what's happening inside Nchan. These are useful for debugging application integration and for measuring performance.
    
    ### Channel Events
    
    Channel events are messages automatically published by Nchan when certain events occur in a channel. These are very useful for debugging the use of channels. However, they carry a significant performance overhead and should be used during development, and not inproduction.
    
    Channel events are published to special 'meta' channels associated with normal channels. Here's how to configure them:
    
    ```nginx
    location ~ /pubsub/(.+)$ {
      nchan_pubsub;
      nchan_channel_id $1;
      nchan_channel_events_channel_id $1; #enables channel events for this location
    }
    
    location ~ /channel_events/(.+) {
      #channel events subscriber location
      nchan_subscriber;
      nchan_channel_group meta; #"meta" is a SPECIAL channel group
      nchan_channel_id $1;
    }
    ```
    
    Note the `/channel_events/...`
    has a *special* `nchan_channel_group`, `meta`. This group is reserved for accessing "channel events channels", or"metachannels".
    
    Now, say I subscribe to `/channel_events/foo` I will refer to this as the channel events subscriber.
    
    Let's see what this channel events subscriber receives when I publish messages to 
    
    Subscribing to `/pubsub/foo` produces the channel event
    ```
    subscriber_enqueue foo
    ```
    
    Publishing a message to `/pubsub/foo`:
    ```
    channel_publish foo
    ```
    
    Unsubscribing from `/pubsub/foo`:
    ```
    subscriber_dequeue foo
    ```
    
    Deleting `/pubsub/foo` (with HTTP `DELETE /pubsub/foo`):
    ```
    channel_delete foo
    ```
    
    The event string itself is configirable with [nchan_channel_event_string](/#nchan_channel_event_string). By default, it is set to `$nchan_channel_event $nchan_channel_id`. 
    This string can use any Nginx and [Nchan variables](/$variables).

    
    ### nchan_stub_status
    
    Like Nginx's [stub_status](https://nginx.org/en/docs/http/ngx_http_stub_status_module.html),
    `nchan_stub_status` is used to get performance metrics.
    
    ```nginx
      location /nchan_stub_status {
        nchan_stub_status;
      }
    ```
    
    Sending a GET request to this location produces the response:
    
    ```text
    total published messages: 1906
    stored messages: 1249
    shared memory used: 1824K
    channels: 80
    subscribers: 90
    redis pending commands: 0
    redis connected servers: 0
    total interprocess alerts received: 1059634
    interprocess alerts in transit: 0
    interprocess queued alerts: 0
    total interprocess send delay: 0
    total interprocess receive delay: 0
    ```
    
    Here's what each line means, and how to interpret it:

%table.nchan-stub-status
  %tr
    %th="total published messages"
    %td="Number of messages published to all channels through this Nchan server."
  %tr
    %th="stored messages"
    %td="Number of messages currently buffered in memory"
  %tr
    %th="shared memory used"
    %td
      :markdown
        Total shared memory used for buffering messages, storing channel information, and other purposes. This value should be comfortably below `nchan_max_reserved_memory`.
  %tr
    %th="channels"
    %td="Number of channels present on this Nchan server."
  %tr
    %th="subscribers"
    %td="Number of subscribers to all channels on this Nchan server."
  %tr
    %th="redis pending commands"
    %td="Number of commands sent to Redis that are awaiting a reply. May spike during high load, especially if the Redis server is overloaded. Should tend towards 0."
  %tr
    %th="redis connected servers"
    %td="Number of redis servers to which Nchan is currently connected."
  %tr
    %th="total interprocess alerts received"
    %td="Number of interprocess communication packets transmitted between Nginx workers processes for Nchan. Can grow at 100-10000 per second at high load."
  %tr
    %th="interprocess alerts in transit"
    %td="Number of interprocess communication packets in transit between Nginx workers. May be nonzero during high load, but should always tend toward 0 over time."
  %tr
    %th="interprocess queued alerts"
    %td="Number of interprocess communication packets waiting to be sent. May be nonzero during high load, but should always tend toward 0 over time."
  %tr
    %th="total interprocess send delay"
    %td="Total amount of time interprocess communication packets spend being queued if delayed. May increase during high load."
  %tr
    %th="total interprocess receive delay"
    %td="Total amount of time interprocess communication packets spend in transit if delayed. May increase during high load."

:markdown
  Additionally, when there is at least one `nchan_stub_status` location, the following Nginx variables are available:
  - `$nchan_stub_status_total_published_messages`  
  - `$nchan_stub_status_stored_messages`  
  - `$nchan_stub_status_shared_memory_used`  
  - `$nchan_stub_status_channels`  
  - `$nchan_stub_status_subscribers`  
  - `$nchan_stub_status_redis_pending_commands`  
  - `$nchan_stub_status_redis_connected_servers`  
  - `$nchan_stub_status_total_ipc_alerts_received`  
  - `$nchan_stub_status_ipc_queued_alerts`  
  - `$nchan_stub_status_total_ipc_send_delay`  
  - `$nchan_stub_status_total_ipc_receive_delay`  
